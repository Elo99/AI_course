Dysarthria is a motor speech disorder often characterized by reduced speech
intelligibility through slow, uncoordinated control of speech production
muscles. Automatic Speech recognition (ASR) systems may help dysarthric talkers
communicate more effectively. To have robust dysarthria-specific ASR,
sufficient training speech is required, which is not readily available. Recent
advances in Text-To-Speech (TTS) synthesis multi-speaker end-to-end TTS systems
suggest the possibility of using synthesis for data augmentation. In this
paper, we aim to improve multi-speaker end-to-end TTS systems to synthesize
dysarthric speech for improved training of a dysarthria-specific DNN-HMM ASR.
In the synthesized speech, we add dysarthria severity level and pause insertion
mechanisms to other control parameters such as pitch, energy, and duration.
Results show that a DNN-HMM model trained on additional synthetic dysarthric
speech achieves WER improvement of 12.2% compared to the baseline, the addition
of the severity level and pause insertion controls decrease WER by 6.5%,
showing the effectiveness of adding these parameters. Audio samples are
available at