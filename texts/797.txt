Training medical image analysis models requires large amounts of expertly
annotated data which is time-consuming and expensive to obtain. Images are
often accompanied by free-text radiology reports which are a rich source of
information. In this paper, we tackle the automated extraction of structured
labels from head CT reports for imaging of suspected stroke patients, using
deep learning. Firstly, we propose a set of 31 labels which correspond to
radiographic findings (e.g. hyperdensity) and clinical impressions (e.g.
haemorrhage) related to neurological abnormalities. Secondly, inspired by
previous work, we extend existing state-of-the-art neural network models with a
label-dependent attention mechanism. Using this mechanism and simple synthetic
data augmentation, we are able to robustly extract many labels with a single
model, classified according to the radiologist's reporting (positive,
uncertain, negative). This approach can be used in further research to
effectively extract many labels from medical text.