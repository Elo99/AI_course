While medical image segmentation is an important task for computer aided
diagnosis, the high expertise requirement for pixelwise manual annotations
makes it a challenging and time consuming task. Since conventional data
augmentations do not fully represent the underlying distribution of the
training set, the trained models have varying performance when tested on images
captured from different sources. Most prior work on image synthesis for data
augmentation ignore the interleaved geometric relationship between different
anatomical labels. We propose improvements over previous GAN-based medical
image synthesis methods by learning the relationship between different
anatomical labels. We use a weakly supervised segmentation method to obtain
pixel level semantic label map of images which is used learn the intrinsic
relationship of geometry and shape across semantic labels. Latent space
variable sampling results in diverse generated images from a base image and
improves robustness. We use the synthetic images from our method to train
networks for segmenting COVID-19 infected areas from lung CT images. The
proposed method outperforms state-of-the-art segmentation methods on a public
dataset. Ablation studies also demonstrate benefits of integrating geometry and
diversity.