Histopathological analysis is the present gold standard for precancerous
lesion diagnosis. The goal of automated histopathological classification from
digital images requires supervised training, which requires a large number of
expert annotations that can be expensive and time-consuming to collect.
Meanwhile, accurate classification of image patches cropped from whole-slide
images is essential for standard sliding window based histopathology slide
classification methods. To mitigate these issues, we propose a carefully
designed conditional GAN model, namely HistoGAN, for synthesizing realistic
histopathology image patches conditioned on class labels. We also investigate a
novel synthetic augmentation framework that selectively adds new synthetic
image patches generated by our proposed HistoGAN, rather than expanding
directly the training set with synthetic images. By selecting synthetic images
based on the confidence of their assigned labels and their feature similarity
to real labeled images, our framework provides quality assurance to synthetic
augmentation. Our models are evaluated on two datasets: a cervical
histopathology image dataset with limited annotations, and another dataset of
lymph node histopathology images with metastatic cancer. Here, we show that
leveraging HistoGAN generated images with selective augmentation results in
significant and consistent improvements of classification performance (6.7% and
2.8% higher accuracy, respectively) for cervical histopathology and metastatic
cancer datasets.