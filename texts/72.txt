In many cases of machine learning, research suggests that the development of
training data might have a higher relevance than the choice and modelling of
classifiers themselves. Thus, data augmentation methods have been developed to
improve classifiers by artificially created training data. In NLP, there is the
challenge of establishing universal rules for text transformations which
provide new linguistic patterns. In this paper, we present and evaluate a text
generation method suitable to increase the performance of classifiers for long
and short texts. We achieved promising improvements when evaluating short as
well as long text tasks with the enhancement by our text generation method.
Especially with regard to small data analytics, additive accuracy gains of up
to 15.53% and 3.56% are achieved within a constructed low data regime, compared
to the no augmentation baseline and another data augmentation technique. As the
current track of these constructed regimes is not universally applicable, we
also show major improvements in several real world low data tasks (up to +4.84
F1-score). Since we are evaluating the method from many perspectives (in total
11 datasets), we also observe situations where the method might not be
suitable. We discuss implications and patterns for the successful application
of our approach on different types of datasets.