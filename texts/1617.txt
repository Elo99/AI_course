In this paper, we propose a method called Hodge and Podge for sound event
detection. We demonstrate Hodge and Podge on the dataset of Detection and
Classification of Acoustic Scenes and Events (DCASE) 2019 Challenge Task 4.
This task aims to predict the presence or absence and the onset and offset
times of sound events in home environments. Sound event detection is
challenging due to the lack of large scale real strongly labeled data. Recently
deep semi-supervised learning (SSL) has proven to be effective in modeling with
weakly labeled and unlabeled data. This work explores how to extend deep SSL to
result in a new, state-of-the-art sound event detection method called Hodge and
Podge. With convolutional recurrent neural networks (CRNN) as the backbone
network, first, a multi-scale squeeze-excitation mechanism is introduced and
added to generate a pyramid squeeze-excitation CRNN. The pyramid
squeeze-excitation layer can pay attention to the issue that different sound
events have different durations, and to adaptively recalibrate channel-wise
spectrogram responses. Further, in order to remedy the lack of real strongly
labeled data problem, we propose multi-hot MixMatch and composition consistency
training with temporal-frequency augmentation. Our experiments with the public
DCASE2019 challenge task 4 validation data resulted in an event-based F-score
of 43.4\%, and is about absolutely 1.6\% better than state-of-the-art methods
in the challenge. While the F-score of the official baseline is 25.8\%.