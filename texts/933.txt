Machine Translation Quality Estimation (QE) is the task of evaluating
translation output in the absence of human-written references. Due to the
scarcity of human-labeled QE data, previous works attempted to utilize the
abundant unlabeled parallel corpora to produce additional training data with
pseudo labels. In this paper, we demonstrate a significant gap between parallel
data and real QE data: for QE data, it is strictly guaranteed that the source
side is original texts and the target side is translated (namely
translationese). However, for parallel data, it is indiscriminate and the
translationese may occur on either source or target side. We compare the impact
of parallel data with different translation directions in QE data augmentation,
and find that using the source-original part of parallel corpus consistently
outperforms its target-original counterpart. Moreover, since the WMT corpus
lacks direction information for each parallel sentence, we train a classifier
to distinguish source- and target-original bitext, and carry out an analysis of
their difference in both style and domain. Together, these findings suggest
using source-original parallel data for QE data augmentation, which brings a
relative improvement of up to 4.0% and 6.4% compared to undifferentiated data
on sentence- and word-level QE tasks respectively.