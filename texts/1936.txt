Data augmentation is an important technique to improve data efficiency and
save labeling cost for 3D detection in point clouds. Yet, existing augmentation
policies have so far been designed to only utilize labeled data, which limits
the data diversity. In this paper, we recognize that pseudo labeling and data
augmentation are complementary, thus propose to leverage unlabeled data for
data augmentation to enrich the training data. In particular, we design three
novel pseudo-label based data augmentation policies (PseudoAugments) to fuse
both labeled and pseudo-labeled scenes, including frames (PseudoFrame), objecta
(PseudoBBox), and background (PseudoBackground). PseudoAugments outperforms
pseudo labeling by mitigating pseudo labeling errors and generating diverse
fused training scenes. We demonstrate PseudoAugments generalize across
point-based and voxel-based architectures, different model capacity and both
KITTI and Waymo Open Dataset. To alleviate the cost of hyperparameter tuning
and iterative pseudo labeling, we develop a population-based data augmentation
framework for 3D detection, named AutoPseudoAugment. Unlike previous works that
perform pseudo-labeling offline, our framework performs PseudoAugments and
hyperparameter tuning in one shot to reduce computational cost. Experimental
results on the large-scale Waymo Open Dataset show our method outperforms
state-of-the-art auto data augmentation method (PPBA) and self-training method
(pseudo labeling). In particular, AutoPseudoAugment is about 3X and 2X data
efficient on vehicle and pedestrian tasks compared to prior arts. Notably,
AutoPseudoAugment nearly matches the full dataset training results, with just
10% of the labeled run segments on the vehicle detection task.