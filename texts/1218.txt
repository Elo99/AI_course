Recent work on decision making and planning for autonomous driving has made
use of game theoretic methods to model interaction between agents. We
demonstrate that methods based on the Stackelberg game formulation of this
problem are susceptible to an issue that we refer to as conflict. Our results
show that when conflict occurs, it causes sub-optimal and potentially dangerous
behaviour. In response, we develop a theoretical framework for analysing the
extent to which such methods are impacted by conflict, and apply this framework
to several existing approaches modelling interaction between agents. Moreover,
we propose Augmented Altruism, a novel approach to modelling interaction
between players in a Stackelberg game, and show that it is less prone to
conflict than previous techniques. Finally, we investigate the behavioural
assumptions that underpin our approach by performing experiments with human
participants. The results show that our model explains human decision-making
better than existing game-theoretic models of interactive driving.