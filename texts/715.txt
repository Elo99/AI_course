Recently, end-to-end (E2E) automatic speech recognition (ASR) systems have
garnered tremendous attention because of their great success and unified
modeling paradigms in comparison to conventional hybrid DNN-HMM ASR systems.
Despite the widespread adoption of E2E modeling frameworks on ASR, there still
is a dearth of work on investigating the E2E frameworks for use in
computer-assisted pronunciation learning (CAPT), particularly for
Mispronunciation detection (MD). In response, we first present a novel use of
hybrid CTCAttention approach to the MD task, taking advantage of the strengths
of both CTC and the attention-based model meanwhile getting around the need for
phone-level forced alignment. Second, we perform input augmentation with text
prompt information to make the resulting E2E model more tailored for the MD
task. On the other hand, we adopt two MD decision methods so as to better
cooperate with the proposed framework: 1) decision-making based on a
recognition confidence measure or 2) simply based on speech recognition
results. A series of Mandarin MD experiments demonstrate that our approach not
only simplifies the processing pipeline of existing hybrid DNN-HMM systems but
also brings about systematic and substantial performance improvements.
Furthermore, input augmentation with text prompts seems to hold excellent
promise for the E2E-based MD approach.