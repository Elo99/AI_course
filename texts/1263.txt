In this paper, we present UR-AIR system submission to the logical access (LA)
and the speech deepfake (DF) tracks of the ASVspoof 2021 Challenge. The LA and
DF tasks focus on synthetic speech detection (SSD), i.e. detecting
text-to-speech and voice conversion as spoofing attacks. Different from
previous ASVspoof challenges, the LA task this year presents codec and
transmission channel variability, while the new task DF presents general audio
compression. Built upon our previous research work on improving the robustness
of the SSD systems to channel effects, we propose a channel-robust synthetic
speech detection system for the challenge. To mitigate the channel variability
issue, we use an acoustic simulator to apply transmission codec, compression
codec, and convolutional impulse responses to augmenting the original datasets.
For the neural network backbone, we propose to use Emphasized Channel
Attention, Propagation and Aggregation Time Delay Neural Networks (ECAPA-TDNN)
as our primary model. We also incorporate one-class learning with
channel-robust training strategies to further learn a channel-invariant speech
representation. Our submission achieved EER 20.33% in the DF task; EER 5.46%
and min-tDCF 0.3094 in the LA task.