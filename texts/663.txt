Span-based joint extraction simultaneously conducts named entity recognition
(NER) and relation extraction (RE) in text span form. However, since previous
span-based models rely on span-level classifications, they cannot benefit from
token-level label information, which has been proven advantageous for the task.
In this paper, we propose a Sequence Tagging augmented Span-based Network
(STSN), a span-based joint model that can make use of token-level label
information. In STSN, we construct a core neural architecture by deep stacking
multiple attention layers, each of which consists of three basic attention
units. On the one hand, the core architecture enables our model to learn
token-level label information via the sequence tagging mechanism and then uses
the information in the span-based joint extraction; on the other hand, it
establishes a bi-directional information interaction between NER and RE.
Experimental results on three benchmark datasets show that STSN consistently
outperforms the strongest baselines in terms of F1, creating new
state-of-the-art results.