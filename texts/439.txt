The pervasiveness of intra-utterance code-switching (CS) in spoken content
requires that speech recognition (ASR) systems handle mixed language. Designing
a CS-ASR system has many challenges, mainly due to data scarcity, grammatical
structure complexity, and domain mismatch. The most common method for
addressing CS is to train an ASR system with the available transcribed CS
speech, along with monolingual data. In this work, we propose a zero-shot
learning methodology for CS-ASR by augmenting the monolingual data with
artificially generating CS text. We based our approach on random lexical
replacements and Equivalence Constraint (EC) while exploiting aligned
translation pairs to generate random and grammatically valid CS content. Our
empirical results show a 65.5% relative reduction in language model perplexity,
and 7.7% in ASR WER on two ecologically valid CS test sets. The human
evaluation of the generated text using EC suggests that more than 80% is of
adequate quality.