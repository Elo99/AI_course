Keystroke inference attacks are a form of side-channel attacks in which an
attacker leverages various techniques to recover a user's keystrokes as she
inputs information into some display (e.g., while sending a text message or
entering her pin). Typically, these attacks leverage machine learning
approaches, but assessing the realism of the threat space has lagged behind the
pace of machine learning advancements, due in-part, to the challenges in
curating large real-life datasets. We aim to overcome the challenge of having
limited number of real data by introducing a video domain adaptation technique
that is able to leverage synthetic data through supervised disentangled
learning. Specifically, for a given domain, we decompose the observed data into
two factors of variation: Style and Content. Doing so provides four learned
representations: real-life style, synthetic style, real-life content and
synthetic content. Then, we combine them into feature representations from all
combinations of style-content pairings across domains, and train a model on
these combined representations to classify the content (i.e., labels) of a
given datapoint in the style of another domain. We evaluate our method on
real-life data using a variety of metrics to quantify the amount of information
an attacker is able to recover. We show that our method prevents our model from
overfitting to a small real-life training set, indicating that our method is an
effective form of data augmentation, thereby making keystroke inference attacks
more practical.