The divergence between labeled training data and unlabeled testing data is a
significant challenge for recent deep learning models. Unsupervised domain
adaptation (UDA) attempts to solve such problem. Recent works show that
self-training is a powerful approach to UDA. However, existing methods have
difficulty in balancing the scalability and performance. In this paper, we
propose a hard-aware instance adaptive self-training framework for UDA on the
task of semantic segmentation. To effectively improve the quality and diversity
of pseudo-labels, we develop a novel pseudo-label generation strategy with an
instance adaptive selector. We further enrich the hard class pseudo-labels with
inter-image information through a skillfully designed hard-aware pseudo-label
augmentation. Besides, we propose the region-adaptive regularization to smooth
the pseudo-label region and sharpen the non-pseudo-label region. For the
non-pseudo-label region, consistency constraint is also constructed to
introduce stronger supervision signals during model optimization. Our method is
so concise and efficient that it is easy to be generalized to other UDA
methods. Experiments on GTA5 to Cityscapes, SYNTHIA to Cityscapes, and
Cityscapes to Oxford RobotCar demonstrate the superior performance of our
approach compared with the state-of-the-art methods.