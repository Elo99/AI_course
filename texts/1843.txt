The data scarcity problem in emotion recognition from electroencephalography
(EEG) leads to difficulty in building an affective model with high accuracy
using machine learning algorithms or deep neural networks. Inspired by emerging
deep generative models, we propose three methods for augmenting EEG training
data to enhance the performance of emotion recognition models. Our proposed
methods are based on two deep generative models, variational autoencoder (VAE)
and generative adversarial network (GAN), and two data augmentation strategies.
For the full usage strategy, all of the generated data are augmented to the
training dataset without judging the quality of the generated data, while for
partial usage, only high-quality data are selected and appended to the training
dataset. These three methods are called conditional Wasserstein GAN (cWGAN),
selective VAE (sVAE), and selective WGAN (sWGAN). To evaluate the effectiveness
of these methods, we perform a systematic experimental study on two public EEG
datasets for emotion recognition, namely, SEED and DEAP. We first generate
realistic-like EEG training data in two forms: power spectral density and
differential entropy. Then, we augment the original training datasets with a
different number of generated realistic-like EEG data. Finally, we train
support vector machines and deep neural networks with shortcut layers to build
affective models using the original and augmented training datasets. The
experimental results demonstrate that the augmented training datasets produced
by our methods enhance the performance of EEG-based emotion recognition models
and outperform the existing data augmentation methods such as conditional VAE,
Gaussian noise, and rotational data augmentation.